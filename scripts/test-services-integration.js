const { KeywordService } = require('../src/services/keyword-service');

async function testIntegratedWorkflow() {
  console.log('ðŸš€ Testing Integrated Keyword Processing Pipeline...\n');

  try {
    // Initialize service
    const settings = {
      semrushApiKey: process.env.SEMRUSH_API_KEY
    };
    
    const keywordService = new KeywordService(settings);
    
    // Test with a small dataset
    const testParams = {
      name: 'integration_test',
      method: 'Domain',
      target: 'htx.com',
      database: 'us',
      limit: 50  // Small test dataset
    };
    
    console.log('ðŸ“Š Processing Parameters:');
    console.log(`  - Method: ${testParams.method}`);
    console.log(`  - Target: ${testParams.target}`);
    console.log(`  - Database: ${testParams.database}`);
    console.log(`  - Limit: ${testParams.limit}\n`);
    
    // Execute full pipeline
    const startTime = Date.now();
    const result = await keywordService.processKeywordRequest(testParams);
    const endTime = Date.now();
    
    // Display results
    console.log('âœ… Pipeline Processing Complete!\n');
    console.log('ðŸ“ˆ Results Summary:');
    console.log(`  - Processing Time: ${(endTime - startTime) / 1000}s`);
    console.log(`  - Raw Keywords Fetched: ${result.keywordCount}`);
    console.log(`  - Processed Keywords: ${result.processedKeywordCount}`);
    console.log(`  - Clusters Found: ${result.clusterCount}`);
    console.log(`  - Duplicate Groups: ${result.duplicateGroupCount}\n`);
    
    // Verify stages completed
    console.log('ðŸ” Pipeline Stages Validation:');
    if (result.stats) {
      console.log(`  âœ“ Keywords Fetched: ${result.stats.keywords_fetched}`);
      console.log(`  âœ“ Keywords Cleaned: ${result.stats.keywords_cleaned}`);
      console.log(`  âœ“ Keywords Unique: ${result.stats.keywords_unique}`);
      console.log(`  âœ“ Keywords Scored: ${result.stats.keywords_scored}`);
      console.log(`  âœ“ Clusters Found: ${result.stats.clusters_found}`);
      console.log(`  âœ“ Duplicate Groups: ${result.stats.duplicate_groups}\n`);
    }
    
    // Verify clusters exist
    if (result.clusters && result.clusters.length > 0) {
      console.log('ðŸŽ¯ Sample Clusters:');
      result.clusters.slice(0, 3).forEach((cluster, index) => {
        console.log(`  ${index + 1}. ${cluster.name || `Cluster ${cluster.id}`}`);
        console.log(`     - Keywords: ${cluster.keyword_count}`);
        console.log(`     - Coherence: ${(cluster.coherence_score || 0).toFixed(3)}`);
        console.log(`     - Search Volume: ${cluster.total_search_volume || 0}`);
      });
      console.log();
    }
    
    // Verify scored keywords exist
    if (result.scoredKeywords && result.scoredKeywords.length > 0) {
      console.log('â­ Top Scored Keywords:');
      result.scoredKeywords.slice(0, 5).forEach((keyword, index) => {
        console.log(`  ${index + 1}. ${keyword.keyword || keyword.cleaned_keyword}`);
        console.log(`     - Priority Score: ${(keyword.priority_score || 0).toFixed(3)}`);
        console.log(`     - Priority Tier: ${keyword.priority_tier || 'unknown'}`);
        console.log(`     - Search Volume: ${keyword.search_volume || 0}`);
      });
      console.log();
    }
    
    console.log('ðŸŽ‰ Integration Test PASSED! All pipeline stages executed successfully.');
    
    return {
      success: true,
      processingTime: endTime - startTime,
      ...result.stats
    };
    
  } catch (error) {
    console.error('âŒ Integration Test FAILED:', error.message);
    console.error('Full error:', error);
    
    return {
      success: false,
      error: error.message
    };
  }
}

// Run test if called directly
if (require.main === module) {
  testIntegratedWorkflow()
    .then(result => {
      console.log('\nðŸ“‹ Test Summary:', result);
      process.exit(result.success ? 0 : 1);
    })
    .catch(error => {
      console.error('Test execution failed:', error);
      process.exit(1);
    });
}

module.exports = { testIntegratedWorkflow };